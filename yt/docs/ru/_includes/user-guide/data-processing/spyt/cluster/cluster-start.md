# Запуск кластера Spark

В данном разделе приведена расширенная инструкция по запуску кластера Spark. Базовые операции по запуску описаны в разделе [Быстрый старт](../../../../../user-guide/data-processing/spyt/launch.md#standalone).

{% note warning "Внимание" %}

Запущенный кластер Spark статически занимает выданные ему ресурсы. По этой причине рекомендуется запускать кластер в отдельном вычислительном пуле с гарантированными ресурсами. Целесообразно поднимать один кластер на команду и переиспользовать ресурсы между несколькими пользователями. Если не планируется высокой интенсивности запуска Spark задач (чаще одного раза в час) — рекомендуется воспользоваться способом [запуска задач напрямую](../../../../../user-guide/data-processing/spyt/launch.md#submit).


{% endnote %}

## Автоскейлер { #auto-scale }

Для экономии ресурсов вычислительного пула в случае низкой нагрузки на Spark возможно включить специальный режим работы, обеспечивающий пропорциональное уменьшение потребляемых ресурсов – автоскейлер.

### Как это работает { #how-works }

У операций {{product-name}} есть метод `update_operation_parameters`, позволяющий изменять параметры операции. Можно менять число джобов в операции через параметр `user_slots`. При изменении параметра планировщик остановит часть джобов или наоборот запустит новые (в пределах лимита, заданного при старте операции). Поскольку планировщик считает, что все джобы в операции одинаковы, в обычном режиме работы Spark подобный способ масштабирования мог бы привести к потере мастера или history-сервера, а так же воркеров, на которых выполняются драйверы джобов Spark. Чтобы недопустить нарушение работы Spark-кластера, реализован механизм его запуска не в виде одной {{product-name}}-операции, а в виде нескольких. В этом случае одна операция выделяется под динамически изменяемый набор воркеров и может масштабироваться в заданных при старте лимитах. В одной или двух других операциях выполняются мастер и history-server (одна операция), драйвер (при запуске драйверов на кластере, вторая операция).


### Как запустить кластер с автоскейлером { #start-auto }

Используются дополнительные параметры для скрипта запуска `spark-launch-yt` или аналогичные параметры клиентской библиотеки SPYT:

- `autoscaler-period <период>` — частота запуска автоскейлера и (потенциально) смены настройки операции, период задается в виде `<длина><единица измерения [d|h|min|s|ms|µs|ns]>`;
- `enable-multi-operation-mode` — включить режим запуска Spark в нескольких {{product-name}}-операциях;
- `enable-dedicated-driver-operation-mode` — запускать воркеры для драйверов в отдельной {{product-name}}-операции;
- `driver-num <кол-во воркеров>` — выделить под драйвер определенное количество воркеров;
- `autoscaler-max-free-workers` — максимальное значение свободных воркеров (все лишние воркеры будут остановлены);
- `autoscaler-slot-increment-step` — шаг увеличения количества воркеров при автоматическом расширении кластера.

Пример:

```bash
$ spark-launch-yt
--proxy <cluster_name>
--autoscaler-period 1s
--enable-multi-operation-mode
--discovery-path //discovery/path
```



## Как обновить кластер { #update-cluster }

Для того чтобы обновить Spark-кластер, необходимо проделать следующие шаги:

1. Остановить операцию с текущим кластером в {{product-name}}. Ссылку на операцию можно найти с помощью `spark-discovery-yt`.
2. Запустить кластер с помощью `spark-launch-yt`. Можно указать в аргументе `spark-cluster-version` нужную версию. Если версия не указана, то будет запущена последняя версия.


